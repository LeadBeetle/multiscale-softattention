{   'adj_mode': <AdjacencyMode.OneStep: 'OneStep'>,
    'batch_size': 256,
    'console_log_freq': 1,
    'dataset_name': <Dataset.CORA: 'Cora'>,
    'do_train_tqdm_logging': False,
    'dropout': 0.6,
    'force_cpu': True,
    'hidden_size': 128,
    'lr': 0.005,
    'model_type': <ModelType.GATV1: 'GAT-V1'>,
    'nbor_degree': 2,
    'num_heads': 1,
    'num_of_epochs': 500,
    'num_of_layers': 2,
    'num_of_runs': 10,
    'num_workers': 0,
    'patience_period': 50,
    'sparse': True,
    'test_batch_size': 256,
    'test_frequency': 1,
    'use_batch_norm': False,
    'use_layer_norm': False}

torch.cuda is available: True
Used Dataset: Cora

Run 01 for GatV1_K2_s and Cora:

Printing only the traceback above the current stack frame
Traceback (most recent call last):
  File "c:\Users\doria\Desktop\ProseminarMA\multiscale-softattention\utils\experimentor_base.py", line 260, in run_wrapper
    self.run()
  File "c:\Users\doria\Desktop\ProseminarMA\multiscale-softattention\utils\experimentor_base.py", line 196, in run
    loss, acc, train_time = self.train(epoch)
  File "c:\Users\doria\Desktop\ProseminarMA\multiscale-softattention\utils\experimentor_base.py", line 123, in train
    out = self.model(self.x[n_id], adjs)
  File "C:\Users\doria\anaconda3\envs\PSN\lib\site-packages\torch\nn\modules\module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "c:\Users\doria\Desktop\ProseminarMA\multiscale-softattention\models\base\Net.py", line 47, in forward
    edge_index, edge_weight = self.one_step_gen(edge_index, self.nbor_degree, x.size(0), self.device)
  File "c:\Users\doria\Desktop\ProseminarMA\multiscale-softattention\utils\utils.py", line 29, in one_step_sparse
    edge_index, edge_weight = remove_self_loops(edge_index, edge_weight)
  File "C:\Users\doria\anaconda3\envs\PSN\lib\site-packages\torch_geometric\utils\loop.py", line 33, in remove_self_loops
    edge_index = edge_index[:, mask]
  File "C:\Users\doria\anaconda3\envs\PSN\lib\site-packages\torch_sparse\tensor.py", line 480, in __getitem__
    out = out.select(dim, item)
  File "C:\Users\doria\anaconda3\envs\PSN\lib\site-packages\torch_sparse\select.py", line 9, in <lambda>
    SparseTensor.select = lambda self, dim, idx: select(self, dim, idx)
  File "C:\Users\doria\anaconda3\envs\PSN\lib\site-packages\torch_sparse\select.py", line 6, in select
    return narrow(src, dim, start=idx, length=1)
  File "C:\Users\doria\anaconda3\envs\PSN\lib\site-packages\torch_sparse\narrow.py", line 50, in narrow
    col = col[mask] - start
RuntimeError: Subtraction, the `-` operator, with a bool tensor is not supported. If you are trying to invert a mask, use the `~` or `logical_not()` operator instead.


Printing the full traceback as if we had not caught it here...
Traceback (most recent call last):
  File "C:\Users\doria\anaconda3\envs\PSN\lib\runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "C:\Users\doria\anaconda3\envs\PSN\lib\runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "C:\Users\doria\anaconda3\envs\PSN\lib\site-packages\ipykernel_launcher.py", line 16, in <module>
    app.launch_new_instance()
  File "C:\Users\doria\anaconda3\envs\PSN\lib\site-packages\traitlets\config\application.py", line 846, in launch_instance
    app.start()
  File "C:\Users\doria\anaconda3\envs\PSN\lib\site-packages\ipykernel\kernelapp.py", line 677, in start
    self.io_loop.start()
  File "C:\Users\doria\anaconda3\envs\PSN\lib\site-packages\tornado\platform\asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "C:\Users\doria\anaconda3\envs\PSN\lib\asyncio\base_events.py", line 570, in run_forever
    self._run_once()
  File "C:\Users\doria\anaconda3\envs\PSN\lib\asyncio\base_events.py", line 1859, in _run_once
    handle._run()
  File "C:\Users\doria\anaconda3\envs\PSN\lib\asyncio\events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "C:\Users\doria\anaconda3\envs\PSN\lib\site-packages\ipykernel\kernelbase.py", line 457, in dispatch_queue
    await self.process_one()
  File "C:\Users\doria\anaconda3\envs\PSN\lib\site-packages\ipykernel\kernelbase.py", line 446, in process_one
    await dispatch(*args)
  File "C:\Users\doria\anaconda3\envs\PSN\lib\site-packages\ipykernel\kernelbase.py", line 353, in dispatch_shell
    await result
  File "C:\Users\doria\anaconda3\envs\PSN\lib\site-packages\ipykernel\kernelbase.py", line 648, in execute_request
    reply_content = await reply_content
  File "C:\Users\doria\anaconda3\envs\PSN\lib\site-packages\ipykernel\ipkernel.py", line 353, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File "C:\Users\doria\anaconda3\envs\PSN\lib\site-packages\ipykernel\zmqshell.py", line 533, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File "C:\Users\doria\anaconda3\envs\PSN\lib\site-packages\IPython\core\interactiveshell.py", line 2898, in run_cell
    result = self._run_cell(
  File "C:\Users\doria\anaconda3\envs\PSN\lib\site-packages\IPython\core\interactiveshell.py", line 2944, in _run_cell
    return runner(coro)
  File "C:\Users\doria\anaconda3\envs\PSN\lib\site-packages\IPython\core\async_helpers.py", line 68, in _pseudo_sync_runner
    coro.send(None)
  File "C:\Users\doria\anaconda3\envs\PSN\lib\site-packages\IPython\core\interactiveshell.py", line 3169, in run_cell_async
    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,
  File "C:\Users\doria\anaconda3\envs\PSN\lib\site-packages\IPython\core\interactiveshell.py", line 3361, in run_ast_nodes
    if (await self.run_code(code, result,  async_=asy)):
  File "C:\Users\doria\anaconda3\envs\PSN\lib\site-packages\IPython\core\interactiveshell.py", line 3441, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File "C:\Users\doria\AppData\Local\Temp/ipykernel_8616/2098744666.py", line 6, in <module>
    runExperiments(models, datasets, degrees, sparse)
  File "c:\Users\doria\Desktop\ProseminarMA\multiscale-softattention\utils\experimentorUtils.py", line 55, in runExperiments
    experimentor.run_wrapper()
  File "c:\Users\doria\Desktop\ProseminarMA\multiscale-softattention\utils\experimentor_base.py", line 260, in run_wrapper
    self.run()
  File "c:\Users\doria\Desktop\ProseminarMA\multiscale-softattention\utils\experimentor_base.py", line 196, in run
    loss, acc, train_time = self.train(epoch)
  File "c:\Users\doria\Desktop\ProseminarMA\multiscale-softattention\utils\experimentor_base.py", line 123, in train
    out = self.model(self.x[n_id], adjs)
  File "C:\Users\doria\anaconda3\envs\PSN\lib\site-packages\torch\nn\modules\module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "c:\Users\doria\Desktop\ProseminarMA\multiscale-softattention\models\base\Net.py", line 47, in forward
    edge_index, edge_weight = self.one_step_gen(edge_index, self.nbor_degree, x.size(0), self.device)
  File "c:\Users\doria\Desktop\ProseminarMA\multiscale-softattention\utils\utils.py", line 29, in one_step_sparse
    edge_index, edge_weight = remove_self_loops(edge_index, edge_weight)
  File "C:\Users\doria\anaconda3\envs\PSN\lib\site-packages\torch_geometric\utils\loop.py", line 33, in remove_self_loops
    edge_index = edge_index[:, mask]
  File "C:\Users\doria\anaconda3\envs\PSN\lib\site-packages\torch_sparse\tensor.py", line 480, in __getitem__
    out = out.select(dim, item)
  File "C:\Users\doria\anaconda3\envs\PSN\lib\site-packages\torch_sparse\select.py", line 9, in <lambda>
    SparseTensor.select = lambda self, dim, idx: select(self, dim, idx)
  File "C:\Users\doria\anaconda3\envs\PSN\lib\site-packages\torch_sparse\select.py", line 6, in select
    return narrow(src, dim, start=idx, length=1)
  File "C:\Users\doria\anaconda3\envs\PSN\lib\site-packages\torch_sparse\narrow.py", line 50, in narrow
    col = col[mask] - start
RuntimeError: Subtraction, the `-` operator, with a bool tensor is not supported. If you are trying to invert a mask, use the `~` or `logical_not()` operator instead.
