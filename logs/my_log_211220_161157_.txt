{   'adj_mode': <AdjacencyMode.Partial: 'Partial'>,
    'aggr_mode': <AggrMode.MAX: 'Max'>,
    'batch_size': 256,
    'computationBefore': False,
    'console_log_freq': 1,
    'dataset_name': <Dataset.CORA: 'Cora'>,
    'do_train_tqdm_logging': False,
    'dropout': 0.6,
    'force_cpu': True,
    'hidden_size': 64,
    'lr': 0.005,
    'model_type': <ModelType.GATV1: 'GAT-V1'>,
    'nbor_degree': 2,
    'num_heads': 4,
    'num_of_epochs': 500,
    'num_of_layers': 2,
    'num_of_runs': 3,
    'num_workers': 0,
    'patience_period': 30,
    'sparse': True,
    'test_batch_size': 256,
    'test_frequency': 1,
    'use_batch_norm': False,
    'use_layer_norm': False}

torch.cuda is available: False
Used Dataset: Cora

Run 01 for GatV1_K2_D2_s_AggrMode.MAX and Cora:

Printing only the traceback above the current stack frame
Traceback (most recent call last):
  File "c:\Users\Projektseminar\VS-Code\multiscale-softattention\utils\experimentor_base.py", line 291, in run_wrapper
    self.run()
  File "c:\Users\Projektseminar\VS-Code\multiscale-softattention\utils\experimentor_base.py", line 221, in run
    loss, acc, train_time = self.train(epoch)
  File "c:\Users\Projektseminar\VS-Code\multiscale-softattention\utils\experimentor_base.py", line 148, in train
    out = self.model(self.x[n_id], adjs)
  File "C:\Users\Projektseminar\anaconda3\envs\PSN\lib\site-packages\torch\nn\modules\module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "c:\Users\Projektseminar\VS-Code\multiscale-softattention\models\base\Net.py", line 74, in forward
    x = self.convs[i]((x, x_target), edge_index, edge_weight)
  File "C:\Users\Projektseminar\anaconda3\envs\PSN\lib\site-packages\torch\nn\modules\module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "c:\Users\Projektseminar\VS-Code\multiscale-softattention\models\ParallelModule.py", line 20, in forward
    return self.aggregate(torch.stack(output, dim=0))
TypeError: expected Tensor as element 0 in argument 0, but got tuple


Printing the full traceback as if we had not caught it here...
Traceback (most recent call last):
  File "C:\Users\Projektseminar\anaconda3\envs\PSN\lib\runpy.py", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File "C:\Users\Projektseminar\anaconda3\envs\PSN\lib\runpy.py", line 87, in _run_code
    exec(code, run_globals)
  File "C:\Users\Projektseminar\anaconda3\envs\PSN\lib\site-packages\ipykernel_launcher.py", line 16, in <module>
    app.launch_new_instance()
  File "C:\Users\Projektseminar\anaconda3\envs\PSN\lib\site-packages\traitlets\config\application.py", line 846, in launch_instance
    app.start()
  File "C:\Users\Projektseminar\anaconda3\envs\PSN\lib\site-packages\ipykernel\kernelapp.py", line 677, in start
    self.io_loop.start()
  File "C:\Users\Projektseminar\anaconda3\envs\PSN\lib\site-packages\tornado\platform\asyncio.py", line 199, in start
    self.asyncio_loop.run_forever()
  File "C:\Users\Projektseminar\anaconda3\envs\PSN\lib\asyncio\base_events.py", line 570, in run_forever
    self._run_once()
  File "C:\Users\Projektseminar\anaconda3\envs\PSN\lib\asyncio\base_events.py", line 1859, in _run_once
    handle._run()
  File "C:\Users\Projektseminar\anaconda3\envs\PSN\lib\asyncio\events.py", line 81, in _run
    self._context.run(self._callback, *self._args)
  File "C:\Users\Projektseminar\anaconda3\envs\PSN\lib\site-packages\ipykernel\kernelbase.py", line 457, in dispatch_queue
    await self.process_one()
  File "C:\Users\Projektseminar\anaconda3\envs\PSN\lib\site-packages\ipykernel\kernelbase.py", line 446, in process_one
    await dispatch(*args)
  File "C:\Users\Projektseminar\anaconda3\envs\PSN\lib\site-packages\ipykernel\kernelbase.py", line 353, in dispatch_shell
    await result
  File "C:\Users\Projektseminar\anaconda3\envs\PSN\lib\site-packages\ipykernel\kernelbase.py", line 648, in execute_request
    reply_content = await reply_content
  File "C:\Users\Projektseminar\anaconda3\envs\PSN\lib\site-packages\ipykernel\ipkernel.py", line 353, in do_execute
    res = shell.run_cell(code, store_history=store_history, silent=silent)
  File "C:\Users\Projektseminar\anaconda3\envs\PSN\lib\site-packages\ipykernel\zmqshell.py", line 533, in run_cell
    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)
  File "C:\Users\Projektseminar\anaconda3\envs\PSN\lib\site-packages\IPython\core\interactiveshell.py", line 2898, in run_cell
    result = self._run_cell(
  File "C:\Users\Projektseminar\anaconda3\envs\PSN\lib\site-packages\IPython\core\interactiveshell.py", line 2944, in _run_cell
    return runner(coro)
  File "C:\Users\Projektseminar\anaconda3\envs\PSN\lib\site-packages\IPython\core\async_helpers.py", line 68, in _pseudo_sync_runner
    coro.send(None)
  File "C:\Users\Projektseminar\anaconda3\envs\PSN\lib\site-packages\IPython\core\interactiveshell.py", line 3169, in run_cell_async
    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,
  File "C:\Users\Projektseminar\anaconda3\envs\PSN\lib\site-packages\IPython\core\interactiveshell.py", line 3361, in run_ast_nodes
    if (await self.run_code(code, result,  async_=asy)):
  File "C:\Users\Projektseminar\anaconda3\envs\PSN\lib\site-packages\IPython\core\interactiveshell.py", line 3441, in run_code
    exec(code_obj, self.user_global_ns, self.user_ns)
  File "C:\Users\PROJEK~1\AppData\Local\Temp/ipykernel_4588/3740305507.py", line 9, in <module>
    runExperiments(models, datasets, degrees, sparse, num_layers, adj_modes, aggr_modes)
  File "c:\Users\Projektseminar\VS-Code\multiscale-softattention\utils\experimentorUtils.py", line 62, in runExperiments
    experimentor.run_wrapper()
  File "c:\Users\Projektseminar\VS-Code\multiscale-softattention\utils\experimentor_base.py", line 291, in run_wrapper
    self.run()
  File "c:\Users\Projektseminar\VS-Code\multiscale-softattention\utils\experimentor_base.py", line 221, in run
    loss, acc, train_time = self.train(epoch)
  File "c:\Users\Projektseminar\VS-Code\multiscale-softattention\utils\experimentor_base.py", line 148, in train
    out = self.model(self.x[n_id], adjs)
  File "C:\Users\Projektseminar\anaconda3\envs\PSN\lib\site-packages\torch\nn\modules\module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "c:\Users\Projektseminar\VS-Code\multiscale-softattention\models\base\Net.py", line 74, in forward
    x = self.convs[i]((x, x_target), edge_index, edge_weight)
  File "C:\Users\Projektseminar\anaconda3\envs\PSN\lib\site-packages\torch\nn\modules\module.py", line 1051, in _call_impl
    return forward_call(*input, **kwargs)
  File "c:\Users\Projektseminar\VS-Code\multiscale-softattention\models\ParallelModule.py", line 20, in forward
    return self.aggregate(torch.stack(output, dim=0))
TypeError: expected Tensor as element 0 in argument 0, but got tuple
{   'adj_mode': <AdjacencyMode.Partial: 'Partial'>,
    'aggr_mode': <AggrMode.MAX: 'Max'>,
    'batch_size': 256,
    'computationBefore': False,
    'console_log_freq': 1,
    'dataset_name': <Dataset.CORA: 'Cora'>,
    'do_train_tqdm_logging': False,
    'dropout': 0.6,
    'force_cpu': True,
    'hidden_size': 64,
    'lr': 0.005,
    'model_type': <ModelType.GATV2: 'GAT-V2'>,
    'nbor_degree': 2,
    'num_heads': 4,
    'num_of_epochs': 500,
    'num_of_layers': 2,
    'num_of_runs': 3,
    'num_workers': 0,
    'patience_period': 30,
    'sparse': True,
    'test_batch_size': 256,
    'test_frequency': 1,
    'use_batch_norm': False,
    'use_layer_norm': False}

torch.cuda is available: False
Used Dataset: Cora

Run 01 for GatV2_K2_D2_s_AggrMode.MAX and Cora:

Epoch 01| Loss: 1.9655| Acc: 0.1286| Train Time: 0.4955s
Train: 0.9286| Val: 0.6140| Test: 0.6200| Eval Time: 0.6346s
Epoch 02| Loss: 1.4953| Acc: 0.8357| Train Time: 0.4904s
Train: 0.9857| Val: 0.7340| Test: 0.7480| Eval Time: 0.6606s
Epoch 03| Loss: 1.0527| Acc: 0.9357| Train Time: 0.4664s
Train: 0.9929| Val: 0.7780| Test: 0.7790| Eval Time: 0.6336s
Epoch 04| Loss: 0.6679| Acc: 0.9857| Train Time: 0.4554s
Train: 1.0000| Val: 0.7820| Test: 0.7910| Eval Time: 0.6136s
Epoch 05| Loss: 0.4054| Acc: 0.9929| Train Time: 0.4804s
Train: 1.0000| Val: 0.7780| Test: 0.7930| Eval Time: 0.6266s
Epoch 06| Loss: 0.2185| Acc: 0.9929| Train Time: 0.4824s
Train: 1.0000| Val: 0.7760| Test: 0.7930| Eval Time: 0.6186s
Epoch 07| Loss: 0.1332| Acc: 1.0000| Train Time: 0.4794s
Train: 1.0000| Val: 0.7780| Test: 0.7950| Eval Time: 0.6226s
Epoch 08| Loss: 0.0603| Acc: 1.0000| Train Time: 0.4614s
Train: 1.0000| Val: 0.7800| Test: 0.7990| Eval Time: 0.6086s
Epoch 09| Loss: 0.0372| Acc: 1.0000| Train Time: 0.4955s
Train: 1.0000| Val: 0.7720| Test: 0.8000| Eval Time: 0.6576s
Epoch 10| Loss: 0.0150| Acc: 1.0000| Train Time: 0.5035s
Train: 1.0000| Val: 0.7740| Test: 0.7950| Eval Time: 0.6676s
Epoch 11| Loss: 0.0096| Acc: 1.0000| Train Time: 0.5275s
Train: 1.0000| Val: 0.7680| Test: 0.7940| Eval Time: 0.6346s
Epoch 12| Loss: 0.0077| Acc: 1.0000| Train Time: 0.4985s
Train: 1.0000| Val: 0.7680| Test: 0.7920| Eval Time: 0.6626s
Epoch 13| Loss: 0.0044| Acc: 1.0000| Train Time: 0.4684s
Train: 1.0000| Val: 0.7660| Test: 0.7910| Eval Time: 0.6376s
Epoch 14| Loss: 0.0023| Acc: 1.0000| Train Time: 0.5215s
Train: 1.0000| Val: 0.7660| Test: 0.7880| Eval Time: 0.6716s
Epoch 15| Loss: 0.0019| Acc: 1.0000| Train Time: 0.5195s
Train: 1.0000| Val: 0.7660| Test: 0.7860| Eval Time: 0.6906s
Epoch 16| Loss: 0.0010| Acc: 1.0000| Train Time: 0.4624s
