{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import torch\r\n",
    "from utils.experimentorUtils import getExperimentor\r\n",
    "from utils.constants import *\r\n",
    "print(torch.backends.cudnn.version())"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "8005\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "config = {\r\n",
    "    \"dataset_name\": Dataset.CORA,\r\n",
    "    \"model_type\": ModelType.GATV1,\r\n",
    "    'num_of_epochs': 500,\r\n",
    "    'num_of_runs': 5,\r\n",
    "    'patience_period': 100,\r\n",
    "    \r\n",
    "    'batch_size': 20000,\r\n",
    "    'test_batch_size': 20000,\r\n",
    "    'num_workers': 2,\r\n",
    "    'force_cpu': False,\r\n",
    "    'test_frequency': 5,\r\n",
    "    'console_log_freq': 1,\r\n",
    "    'do_train_tqdm_logging': False,\r\n",
    "    \r\n",
    "    'lr': 0.005,\r\n",
    "    'num_of_layers': 2, \r\n",
    "    'num_heads': 1,\r\n",
    "    'hidden_size': 128,\r\n",
    "    'dropout': 0.6,  \r\n",
    "    \"use_layer_norm\": False,\r\n",
    "    \"use_batch_norm\": False,\r\n",
    "    \r\n",
    "    'nbor_degree': 1,\r\n",
    "    'adj_mode': AdjacencyMode.OneStep,\r\n",
    "    'sparse': True\r\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "for isSparse in [False, True]:\r\n",
    "    config[\"sparse\"] = isSparse\r\n",
    "    for dataset in [Dataset.CORA, Dataset.PUBMED, Dataset.CITESEER]:\r\n",
    "        config[\"dataset_name\"] = dataset\r\n",
    "        if dataset == Dataset.PUBMED:\r\n",
    "                config[\"lr\"] = 0.01\r\n",
    "                config[\"num_heads\"] = 8\r\n",
    "        else: \r\n",
    "            config[\"lr\"] = 0.005\r\n",
    "            config[\"num_heads\"] = 1\r\n",
    "            \r\n",
    "        for degree in [1, 2, 3, 4]:\r\n",
    "            config[\"nbor_degree\"] = degree\r\n",
    "            experimentor = getExperimentor(config[\"dataset_name\"])(config)\r\n",
    "            experimentor.run_wrapper()"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Run 01:\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epoch 01: 100%|██████████| 140/140 [00:02<00:00, 51.00it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 01| Loss: 1.9812| Acc: 0.1357| Train Time: 2.7513s\n",
      "Epoch 02| Loss: 1.5675| Acc: 0.6286| Train Time: 2.8942s\n",
      "Epoch 03| Loss: 1.1340| Acc: 0.8429| Train Time: 2.9835s\n",
      "Epoch 04| Loss: 0.9629| Acc: 0.8714| Train Time: 2.3089s\n",
      "Epoch 05| Loss: 0.6765| Acc: 0.9500| Train Time: 2.2331s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Evaluating: 100%|██████████| 5416/5416 [00:06<00:00, 867.65it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train: 0.9857| Val: 0.7700| Test: 0.7900| Eval Time: 6.2472s\n",
      "Epoch 06| Loss: 0.5021| Acc: 0.9643| Train Time: 2.7350s\n",
      "Epoch 07| Loss: 0.3338| Acc: 0.9786| Train Time: 2.2676s\n",
      "Epoch 08| Loss: 0.3267| Acc: 0.9857| Train Time: 2.3113s\n",
      "Epoch 09| Loss: 0.2649| Acc: 0.9929| Train Time: 2.3234s\n",
      "Epoch 10| Loss: 0.1766| Acc: 1.0000| Train Time: 2.2882s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Evaluating: 100%|██████████| 5416/5416 [00:04<00:00, 1203.01it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train: 1.0000| Val: 0.7580| Test: 0.7680| Eval Time: 4.5060s\n",
      "Epoch 11| Loss: 0.1342| Acc: 0.9929| Train Time: 2.1625s\n",
      "Epoch 12| Loss: 0.1619| Acc: 0.9929| Train Time: 2.2092s\n",
      "Epoch 13| Loss: 0.1103| Acc: 0.9929| Train Time: 2.1831s\n",
      "Epoch 14| Loss: 0.0836| Acc: 0.9929| Train Time: 2.1828s\n",
      "Epoch 15| Loss: 0.0921| Acc: 0.9929| Train Time: 2.1525s\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Evaluating: 100%|██████████| 5416/5416 [00:04<00:00, 1226.00it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train: 1.0000| Val: 0.7460| Test: 0.7650| Eval Time: 4.4216s\n",
      "Epoch 16| Loss: 0.0659| Acc: 1.0000| Train Time: 2.2078s\n",
      "Epoch 17| Loss: 0.0510| Acc: 1.0000| Train Time: 2.1546s\n",
      "Epoch 18| Loss: 0.0646| Acc: 1.0000| Train Time: 2.3256s\n",
      "Epoch 19| Loss: 0.0314| Acc: 1.0000| Train Time: 2.7863s\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('PS': conda)"
  },
  "interpreter": {
   "hash": "1322c26f02ebbf0700fad666a69e487b987002dd3640f1a2df48e494c6ae2c9b"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}